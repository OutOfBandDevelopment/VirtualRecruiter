services:

  apache-tika:
    extends:
      file: docker-compose.apache-tika.yaml
      service: apache-tika
    networks:
    - backend
    ports:
    - ${SERVER_PORT_APACHE_TIKA}:9998
    restart: 'unless-stopped'

  ollama:
    extends:
      file: docker-compose.ollama.yaml
      service: ollama
    networks:
    - backend
    ports:
    - ${SERVER_PORT_OLLAMA}:11434
    restart: 'unless-stopped'
    # deploy:
    #   resources:
    #     reservations:
    #       devices:
    #         - driver: nvidia
    #           count: 1
    #           capabilities: [gpu]

  searxng:
    extends:
      file: docker-compose.searxng.yaml
      service: searxng
    networks:
    - backend
    ports:
      - ${SERVER_PORT_SEARXNG}:8080
    restart: 'unless-stopped'

  open-webui:
    extends:
      file: docker-compose.open-web-ui.yaml
      service: open-webui
    # environment:
    #   USE_CUDA_DOCKER: True
    depends_on:
    - ollama
    - searxng
    - apache-tika
    networks:
    - frontend
    - backend
    ports:
    - ${SERVER_PORT_OPEN_WEBUI}:8080
    restart: 'unless-stopped'
    # deploy:
    #   resources:
    #     reservations:
    #       devices:
    #         - driver: nvidia
    #           count: 1
    #           capabilities: [gpu]
      

networks:
  frontend:
    driver: bridge
  backend:
    driver: bridge
    
volumes:
    open-webui-docs:
    open-webui-data:
    ollama-models:
